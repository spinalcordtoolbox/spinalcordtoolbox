{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1cc26a7",
   "metadata": {},
   "source": [
    "# Keras vs. ONNX model output comparison\n",
    "\n",
    "This notebook can be used to generate predictions for sct_example_data and sct_testing data using both the Keras and ONNX deepseg models. It can then be used to compare both sets of predictions to ensure that identical results are preserved.\n",
    "\n",
    "The steps used are as follows:\n",
    "\n",
    "### 1. Generating Keras predictions from `master`\n",
    "\n",
    "> Note: To save time, you can instead extract the sample generated Keras predictions from this [data_keras.zip](https://github.com/spinalcordtoolbox/spinalcordtoolbox/files/8399211/data_keras.zip) into your `$SCT_DIR/data` folder. Then, you can skip right to generating the ONNX Files.\n",
    "\n",
    "1. Install SCT using the `master` branch.\n",
    "    - Both Keras and Tensorflow should be installed in the `venv_sct` environment.\n",
    "2. In the first cell, change `dataset_name` to `\"sct_example_data\"`. Then, go to Kernel -> Restart & Run All.\n",
    "    - The second cell should output `\"Using keras models on b'master\\n' branch...\"`\n",
    "    - 16 files ending in `_keras.nii.gz` should be generated. (2 dmri, 3 t1, 5 t2, and 6 t2s)\n",
    "3. In the first cell, change `dataset_name` to `\"sct_testing_data\"`. Then, go to Kernel -> Restart & Run All.\n",
    "    - The same output files should be generated, just for a different dataset.\n",
    " \n",
    "### 2. Generating ONNX predictions from `jn/3735` + comparing Keras/ONNX \n",
    "\n",
    "> Note: To save time, you can instead extract the sample generated ONNX predictions from this [data_onnx.zip](https://github.com/spinalcordtoolbox/spinalcordtoolbox/files/8399209/data_onnx.zip) into your `$SCT_DIR/data` folder. Then, you can choose to only run the first and last cells in this notebook, instead of running all of the cells.\n",
    "\n",
    "1. Switch to the `jn/3735-replace-tensorflow-with-onnxruntime` branch and install SCT.\n",
    "   - Neither Keras nor Tensorflow should be installed in the `venv_sct` environment.\n",
    "   - Note: It may be less of a hassle to keep two separate installations (e.g. in two separate working environments), rather than overwriting the existing installation.\n",
    "2. Ensure that you have the previously-mentioned `_keras.nii.gz` files in your `data/sct_example_data/` and `data/sct_testing_data/` folders.\n",
    "2. In the first cell, change `dataset_name` to `\"sct_example_data\"`. Then, go to Kernel -> Restart & Run All.\n",
    "    - The second cell should output `\"Using onnx models on b'jn/3735-replace-tensorflow-with-onnxruntime\\n' branch...\"`\n",
    "    - 16 files ending in `_onnx.nii.gz` should be generated. (2 dmri, 3 t1, 5 t2, and 6 t2s)\n",
    "    - These files should be checked against the `_keras.nii.gz` files in the last cell of the notebook.\n",
    "3. In the first cell, change `dataset_name` to `\"sct_testing_data\"`. Then, go to Kernel -> Restart & Run All.\n",
    "    - The same output files should be generated, just for a different dataset.\n",
    "    - These files should be checked against the `_keras.nii.gz` files in the last cell of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb56ab7",
   "metadata": {},
   "source": [
    "### Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29f4792",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from spinalcordtoolbox.scripts import sct_download_data\n",
    "from spinalcordtoolbox.utils import __data_dir__\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "dataset_name = \"sct_example_data\"\n",
    "\n",
    "sct_download_data.main([\"-d\", dataset_name, \"-k\"])\n",
    "\n",
    "# In sct_testing_data, for some reason the T1-weighted file is called 't1w.nii.gz' (instead of 't1.nii.gz' like it \n",
    "# is in sct_example_data. 't1.nii.gz' is much easier to work with, because 't1' is used for both the folder name \n",
    "# and the `-c` contrast. So, we generate a copy called 't1.nii.gz'.\n",
    "if dataset_name is \"sct_testing_data\":\n",
    "    shutil.copyfile(os.path.join(__data_dir__, dataset_name, \"t1\", \"t1w.nii.gz\"),\n",
    "                    os.path.join(__data_dir__, dataset_name, \"t1\", \"t1.nii.gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57ee539",
   "metadata": {},
   "source": [
    "### Git branch setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb1952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "branch = subprocess.run(\"git rev-parse --abbrev-ref HEAD\", capture_output=True, shell=True).stdout\n",
    "if b\"jn/3735-replace-tensorflow-with-onnxruntime\" in branch:\n",
    "    suffix = \"onnx\"\n",
    "else:\n",
    "    suffix = \"keras\"\n",
    "    \n",
    "print(f\"Using {suffix} models on {branch} branch...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967272b3",
   "metadata": {},
   "source": [
    "### Inference using sct_deepseg_sc models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdead2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import onnxruntime as ort\n",
    "\n",
    "from spinalcordtoolbox.scripts import sct_deepseg_sc, sct_dmri_separate_b0_and_dwi\n",
    "from spinalcordtoolbox.utils import __data_dir__, sct_dir_local_path\n",
    "from spinalcordtoolbox.image import Image\n",
    "from spinalcordtoolbox.deepseg_sc.core import heatmap\n",
    "from spinalcordtoolbox.resampling import resample_nib\n",
    "\n",
    "for contrast in [\"dwi\", \"t1\", \"t2\", \"t2s\"]:\n",
    "    # 1. Isolate spinal cord segmentation (to evaluate 2D/3D spinal cord segmentation models)\n",
    "    if contrast is \"dwi\":\n",
    "        # The reason \"dwi\" is done separately is because it has some quirks:\n",
    "        #   - no '3d kernel' model\n",
    "        #   - folder name (\"dmri\") is different from contrast name (\"dwi\")\n",
    "        #   - requires preprocessing (4d image -> 3d image)\n",
    "        path_data = os.path.join(__data_dir__, dataset_name, \"dmri\")\n",
    "        sct_dmri_separate_b0_and_dwi.main([\"-i\", os.path.join(path_data, \"dmri.nii.gz\"),\n",
    "                                           \"-bvec\", os.path.join(path_data, \"bvecs.txt\"),\n",
    "                                           \"-ofolder\", path_data])\n",
    "        path_in = os.path.join(path_data, \"dmri_dwi_mean.nii.gz\")\n",
    "        path_out = os.path.join(path_data, f\"{contrast}_seg_2d_{suffix}.nii.gz\")\n",
    "        sct_deepseg_sc.main([\"-i\", path_in, \"-c\", contrast, \"-kernel\", \"2d\", \n",
    "                             \"-centerline\", \"cnn\", \"-ofolder\", path_data, \"-o\", path_out])\n",
    "    else:\n",
    "        # All other contrasts can be processed using the same steps\n",
    "        path_data = os.path.join(__data_dir__, dataset_name, contrast)\n",
    "        path_in = os.path.join(path_data, f\"{contrast}.nii.gz\")\n",
    "        for kernel_type in [\"2d\", \"3d\"]:\n",
    "            path_out = os.path.join(path_data, f\"{contrast}_seg_{kernel_type}_{suffix}.nii.gz\")\n",
    "            sct_deepseg_sc.main([\"-i\", path_in, \"-c\", contrast, \"-kernel\", kernel_type, \n",
    "                                 \"-centerline\", \"cnn\", \"-ofolder\", path_data, \"-o\", path_out])\n",
    "    \n",
    "    # 2. Isolate centerline heatmaps (to evaluate centerline detection models)\n",
    "    # - NB: This section involves quite a lot of copying and pasting from SCT's source code,\n",
    "    #       in order to call the `heatmap()` function and access the 'im_heatmap' variable directly.\n",
    "    im = Image(path_in)\n",
    "    im.change_orientation('RPI')\n",
    "    im_res = resample_nib(im, new_size=[0.5, 0.5, im.dim[6]], new_size_type='mm', interpolation='linear')\n",
    "    dct_patch_ctr = {'t2': {'size': (80, 80), 'mean': 51.1417, 'std': 57.4408},\n",
    "                     't2s': {'size': (80, 80), 'mean': 68.8591, 'std': 71.4659},\n",
    "                     't1': {'size': (80, 80), 'mean': 55.7359, 'std': 64.3149},\n",
    "                     'dwi': {'size': (80, 80), 'mean': 55.744, 'std': 45.003}}\n",
    "    dct_params_ctr = {'t2': {'features': 16, 'dilation_layers': 2},\n",
    "                      't2s': {'features': 8, 'dilation_layers': 3},\n",
    "                      't1': {'features': 24, 'dilation_layers': 3},\n",
    "                      'dwi': {'features': 8, 'dilation_layers': 2}}\n",
    "    if suffix is \"onnx\":\n",
    "        ctr_model_fname = sct_dir_local_path('data', 'deepseg_sc_models', '{}_ctr.onnx'.format(contrast))\n",
    "        ort_sess = ort.InferenceSession(ctr_model_fname)\n",
    "        im_heatmap, z_max = heatmap(im=im_res,\n",
    "                                    contrast_type=contrast,\n",
    "                                    model=ort_sess,\n",
    "                                    patch_shape=dct_patch_ctr[contrast]['size'],\n",
    "                                    mean_train=dct_patch_ctr[contrast]['mean'],\n",
    "                                    std_train=dct_patch_ctr[contrast]['std'])\n",
    "    else:\n",
    "        from spinalcordtoolbox.deepseg_sc.cnn_models import nn_architecture_ctr\n",
    "        ctr_model_fname = sct_dir_local_path('data', 'deepseg_sc_models', '{}_ctr.h5'.format(contrast))\n",
    "        ctr_model = nn_architecture_ctr(height=dct_patch_ctr[contrast]['size'][0],\n",
    "                                        width=dct_patch_ctr[contrast]['size'][1],\n",
    "                                        channels=1,\n",
    "                                        classes=1,\n",
    "                                        features=dct_params_ctr[contrast]['features'],\n",
    "                                        depth=2,\n",
    "                                        temperature=1.0,\n",
    "                                        padding='same',\n",
    "                                        batchnorm=True,\n",
    "                                        dropout=0.0,\n",
    "                                        dilation_layers=dct_params_ctr[contrast]['dilation_layers'])\n",
    "        ctr_model.load_weights(ctr_model_fname)\n",
    "        im_heatmap, z_max = heatmap(im=im_res,\n",
    "                                    model=ctr_model,\n",
    "                                    patch_shape=dct_patch_ctr[contrast]['size'],\n",
    "                                    mean_train=dct_patch_ctr[contrast]['mean'],\n",
    "                                    std_train=dct_patch_ctr[contrast]['std'])\n",
    "    im_heatmap.save(os.path.join(path_data, f\"{contrast}_ctr_heatmap_{suffix}.nii.gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e856a2",
   "metadata": {},
   "source": [
    "### Inference using sct_deepseg_gm models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193e1891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from spinalcordtoolbox.scripts import sct_deepseg_gm\n",
    "\n",
    "# NB: This code is the same regardless of whether the model is Keras or ONNX,\n",
    "#     because the branch changes will take care of everything.\n",
    "for contrast in [\"t2s\"]:\n",
    "    for model in [\"large\", \"challenge\"]:\n",
    "        path_data = os.path.join(__data_dir__, dataset_name, contrast)\n",
    "        path_in = os.path.join(path_data, f\"{contrast}.nii.gz\")\n",
    "        path_out = os.path.join(path_data, f\"{contrast}_seg_gm_{model}_{suffix}.nii.gz\")\n",
    "        sct_deepseg_gm.main(['-i', path_in, '-m', model, '-o', path_out])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dd40f7",
   "metadata": {},
   "source": [
    "### Inference using sct_deepseg_lesion models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a63c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from spinalcordtoolbox.scripts import sct_deepseg_lesion\n",
    "from spinalcordtoolbox.deepseg_lesion.core import segment_3d\n",
    "from spinalcordtoolbox.utils import __sct_dir__\n",
    "\n",
    "for contrast in [\"t2\", \"t2_ax\", \"t2s\"]:\n",
    "    if contrast is \"t2s\":\n",
    "        path_data = os.path.join(__data_dir__, dataset_name, \"t2s\")\n",
    "    elif contrast in [\"t2\", \"t2_ax\"]:\n",
    "        path_data = os.path.join(__data_dir__, dataset_name, \"t2\")\n",
    "    path_in = os.path.join(path_data, f\"{contrast}_lesion.nii.gz\")\n",
    "    path_out = os.path.join(path_data, f\"{contrast}_seg_lesion_{suffix}.nii.gz\")\n",
    "    \n",
    "    # create fake data containing:\n",
    "    # - Spinal cord voxels\n",
    "    # - CSF voxels\n",
    "    # - A fake lesion\n",
    "    data = np.zeros((48, 48, 96))\n",
    "    xx, yy = np.mgrid[:48, :48]\n",
    "    circle = (xx - 24) ** 2 + (yy - 24) ** 2\n",
    "    # iterating slice by slice in z axis to create a cylindrical-shaped CSF + SC\n",
    "    for zz in range(data.shape[2]): \n",
    "        data[:,:,zz] += np.logical_and(circle < 400, circle >= 200) * 2400  # intensity = CSF\n",
    "        data[:,:,zz] += (circle < 200)                              * 500   # intensity = SC\n",
    "    data[16:22, 16:22, 64:90]                                       = 1000  # intensity = fake lesion\n",
    "    # NB: While these shapes and contrast values are appropriate for the \"t2\" contrast,\n",
    "    #     they likely aren't appropriate for \"t2_ax\" (b/c orientation) and \"t2s\" (b/c intensity values)\n",
    "    #     So, this step should be amended for those contrast options.\n",
    "    \n",
    "    # create image using data and save to file\n",
    "    affine = np.eye(4)\n",
    "    nii = nib.nifti1.Nifti1Image(data, affine)\n",
    "    img = Image(data, hdr=nii.header, dim=nii.header.get_data_shape())\n",
    "    img.save(path_in)\n",
    "    \n",
    "    # NB: We can't run the full sct_deepseg_lesion and compare the outputs unless we create \n",
    "    #     more realistic lesion data, as the CLI script uses additional steps (e.g resampling)\n",
    "    #     Otherwise, we would run this command instead:\n",
    "    # sct_deepseg_lesion.main([\"-i\", path_in, \"-c\", contrast, \"-ofolder\", path_data])\n",
    "    \n",
    "    # So instead, we segment fake lesion data by calling `segment_3d()` directly\n",
    "    if suffix is \"onnx\":\n",
    "        model_path = os.path.join(__sct_dir__, 'data', 'deepseg_lesion_models', f'{contrast}_lesion.onnx')\n",
    "    else:\n",
    "        model_path = os.path.join(__sct_dir__, 'data', 'deepseg_lesion_models', f'{contrast}_lesion.h5')\n",
    "    seg = segment_3d(model_path, contrast, img.copy())\n",
    "    seg.save(path_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a910ca",
   "metadata": {},
   "source": [
    "### Comparing Keras-generated files to ONNX-generated files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c91d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from spinalcordtoolbox.image import Image\n",
    "\n",
    "path_data = os.path.join(__data_dir__, dataset_name)\n",
    "data_files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(path_data) for f in filenames]\n",
    "\n",
    "for filepath in data_files:\n",
    "    if \"_onnx\" in filepath:\n",
    "        keras_filepath = filepath.replace(\"_onnx.nii.gz\", \"_keras.nii.gz\")\n",
    "        if not os.path.isfile(keras_filepath):\n",
    "            print(f\"{filepath} present, but missing corresponding {keras_filepath}!\")\n",
    "        else:\n",
    "            data_onnx = Image(filepath).data\n",
    "            data_keras = Image(keras_filepath).data\n",
    "            print(f\"Checking {filepath}... {(data_onnx==data_keras).all()}\")\n",
    "            \n",
    "    elif \"_keras\" in filepath:\n",
    "        onnx_filepath = filepath.replace(\"_keras.nii.gz\", \"_onnx.nii.gz\")\n",
    "        if not os.path.isfile(onnx_filepath):\n",
    "            print(f\"{filepath} present, but missing corresponding {onnx_filepath}!\")\n",
    "        else:\n",
    "            pass\n",
    "    else:      \n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
