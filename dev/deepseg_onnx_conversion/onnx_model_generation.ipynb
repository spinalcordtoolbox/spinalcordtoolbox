{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24130084",
   "metadata": {},
   "source": [
    "# Converting SCT's Keras models into the .ONNX representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e8dad4",
   "metadata": {},
   "source": [
    "## 1 sct_deepseg_sc models\n",
    "\n",
    "Notes:\n",
    "* In the \"ctr\", \"2d\", and \"3d\" cases, some code had to be copied and pasted from `core.py`, because the original Keras model-generating code wasn't well encapsulated.\n",
    "* When generating the ONNX model, opset 11 is needed because it corresponds to ir_version=6:\n",
    "   * opset 15 and above (ir_version=8) isn't compatible with present versions of onnxruntime\n",
    "   * opset 13/14 (ir_version=7) caused a warning that I forgot to document well\n",
    "   * opset 12 (ir_version=7) caused a warning when converting the 3D model specifically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741cdaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras2onnx\n",
    "from keras import backend as K\n",
    "from spinalcordtoolbox.utils import sct_dir_local_path\n",
    "\n",
    "TARGET_OPSET = 11\n",
    "output_names = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1657fbeb",
   "metadata": {},
   "source": [
    "### 1.1 Centerline detection models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c89c6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dev.deepseg_sc.cnn_models import nn_architecture_ctr\n",
    "\n",
    "for contrast_type in ['t1', 't2', 't2s', 'dwi']:\n",
    "    # NB: This is needed to reset the layer numbers, so that each model has identically named layers\n",
    "    #     https://stackoverflow.com/questions/49123194/keras-reset-layer-numbers\n",
    "    K.clear_session()\n",
    "    \n",
    "    # 1.1a Loading Keras model\n",
    "    dct_patch_ctr = {'t2': {'size': (80, 80), 'mean': 51.1417, 'std': 57.4408},\n",
    "                     't2s': {'size': (80, 80), 'mean': 68.8591, 'std': 71.4659},\n",
    "                     't1': {'size': (80, 80), 'mean': 55.7359, 'std': 64.3149},\n",
    "                     'dwi': {'size': (80, 80), 'mean': 55.744, 'std': 45.003}}\n",
    "    dct_params_ctr = {'t2': {'features': 16, 'dilation_layers': 2},\n",
    "                      't2s': {'features': 8, 'dilation_layers': 3},\n",
    "                      't1': {'features': 24, 'dilation_layers': 3},\n",
    "                      'dwi': {'features': 8, 'dilation_layers': 2}}\n",
    "    ctr_model_fname = sct_dir_local_path('data', 'deepseg_sc_models', '{}_ctr.h5'.format(contrast_type))\n",
    "    ctr_model = nn_architecture_ctr(height=dct_patch_ctr[contrast_type]['size'][0],\n",
    "                                    width=dct_patch_ctr[contrast_type]['size'][1],\n",
    "                                    channels=1,\n",
    "                                    classes=1,\n",
    "                                    features=dct_params_ctr[contrast_type]['features'],\n",
    "                                    depth=2,\n",
    "                                    temperature=1.0,\n",
    "                                    padding='same',\n",
    "                                    batchnorm=True,\n",
    "                                    dropout=0.0,\n",
    "                                    dilation_layers=dct_params_ctr[contrast_type]['dilation_layers'])\n",
    "    ctr_model.load_weights(ctr_model_fname)\n",
    "    # print(ctr_model.summary())\n",
    "    \n",
    "    # 1.1b Saving ONNX model\n",
    "    ctr_model_fname_out = sct_dir_local_path('data', 'deepseg_sc_models', '{}_ctr.onnx'.format(contrast_type))\n",
    "    if not os.path.isfile(ctr_model_fname_out):\n",
    "        onnx_model = keras2onnx.convert_keras(ctr_model, f'ctr_model_{contrast_type}', target_opset=TARGET_OPSET)\n",
    "        keras2onnx.save_model(onnx_model, ctr_model_fname_out)\n",
    "        output_names[f\"{contrast_type}_ctr\"] = [n.name for n in onnx_model.graph.output]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9e0205",
   "metadata": {},
   "source": [
    "### 1.2 2D patch spinal cord segmentation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0b0fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dev.deepseg_sc.cnn_models import nn_architecture_seg\n",
    "\n",
    "kernel_size = '2d'\n",
    "for contrast_type in ['t1', 't2', 't2s', 'dwi']:\n",
    "    # NB: This is needed to reset the layer numbers, so that each model has identically named layers\n",
    "    #     https://stackoverflow.com/questions/49123194/keras-reset-layer-numbers\n",
    "    K.clear_session()\n",
    "    \n",
    "    # 1.2a Loading Keras model\n",
    "    crop_size = 96 if (kernel_size == '3d' and contrast_type == 't2s') else 64  # Unnecessary, but preserved for posterity\n",
    "    input_size = (crop_size, crop_size)\n",
    "    seg_model_2d = nn_architecture_seg(height=input_size[0],\n",
    "                                       width=input_size[1],\n",
    "                                       depth=2 if contrast_type != 't2' else 3,\n",
    "                                       features=32,\n",
    "                                       batchnorm=False,\n",
    "                                       dropout=0.0)\n",
    "    model_fname_2d = sct_dir_local_path('data', 'deepseg_sc_models', '{}_sc.h5'.format(contrast_type))\n",
    "    seg_model_2d.load_weights(model_fname_2d)\n",
    "    # print(seg_model_2d.summary())\n",
    "        \n",
    "    # 1.2b Saving ONNX model\n",
    "    model_fname_2d_out = sct_dir_local_path('data', 'deepseg_sc_models', '{}_sc.onnx'.format(contrast_type))\n",
    "    if not os.path.isfile(model_fname_2d_out):\n",
    "        onnx_model = keras2onnx.convert_keras(seg_model_2d, f'sc_2d_model_{contrast_type}', target_opset=TARGET_OPSET)\n",
    "        keras2onnx.save_model(onnx_model, model_fname_2d_out)\n",
    "        output_names[f\"{contrast_type}_2d\"] = [n.name for n in onnx_model.graph.output]           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4f0eaa",
   "metadata": {},
   "source": [
    "### 1.3 3D patch spinal cord segmentation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724efa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dev.deepseg_sc.cnn_models_3d import load_trained_model, nn_architecture_seg_3d\n",
    "\n",
    "kernel_size = '3d'\n",
    "for contrast_type in ['t1', 't2', 't2s']:  # NB: There is no 'dwi' 3D patch model (?)\n",
    "    # NB: This is needed to reset the layer numbers, so that each model has identically named layers\n",
    "    #     https://stackoverflow.com/questions/49123194/keras-reset-layer-numbers\n",
    "    K.clear_session()\n",
    "    \n",
    "    # 1.3a Loading Keras model\n",
    "    model_fname_3d = sct_dir_local_path('data', 'deepseg_sc_models', '{}_sc_3D.h5'.format(contrast_type))\n",
    "    # - NB: The inference code in SCT uses \"load_trained_model()\" instead of the actual model architecture, e.g.:\n",
    "    #\n",
    "    #     seg_model_3d_old = load_trained_model(model_fname_3d)    \n",
    "    #     print(seg_model_3d_old.summary())\n",
    "    #\n",
    "    # - This works, but we want to change the output layer name, so we need to use `nn_architecture_seg_3d` like\n",
    "    #   we do with `nn_architecture_seg` and `nn_architecture_ctr` in the earlier steps.\n",
    "    # - The problem is, the call to `nn_architecture_seg_3d` was undocumented, so I had to guess at which \n",
    "    #   parameters would create the correct architecture. \n",
    "    # - I also had to fix a bug in `nn_architecture_seg_3d`. \n",
    "    # - Because of these factors, it is dubious whether the call to `nn_architecture_seg_3d` actually produces\n",
    "    #   the correct ONNX file. So, the generated model file should be tested extensively.\n",
    "    crop_size = 96 if (kernel_size == '3d' and contrast_type == 't2s') else 64  # from deepseg_sc/core.py\n",
    "    seg_model_3d = nn_architecture_seg_3d(input_shape=(1, crop_size, crop_size, 48), n_base_filters=24, depth=2)\n",
    "    seg_model_3d.load_weights(model_fname_3d)\n",
    "    # print(seg_model_3d.summary())\n",
    "    \n",
    "    # 1.3b Saving ONNX model\n",
    "    model_fname_3d_out = sct_dir_local_path('data', 'deepseg_sc_models', '{}_sc_3D.onnx'.format(contrast_type))\n",
    "    if not os.path.isfile(model_fname_3d_out):\n",
    "        onnx_model = keras2onnx.convert_keras(seg_model_3d, f'sc_3d_model_{contrast_type}', target_opset=TARGET_OPSET)\n",
    "        keras2onnx.save_model(onnx_model, model_fname_3d_out)\n",
    "        output_names[f\"{contrast_type}_3d\"] = [n.name for n in onnx_model.graph.output]   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559f4fc9",
   "metadata": {},
   "source": [
    "## 2. sct_deepseg_gm models\n",
    "\n",
    "There is a slight snag with the sct_deepseg_gm models: The input layer doesn't have a fixed size; instead, it gets created on the fly based on the size of the input image:\n",
    "\n",
    "```python\n",
    "    ### Inside deepseg_gm.py :: segment_volume()\n",
    "    if small_input:\n",
    "        # Smaller than the trained net, don't crop\n",
    "        net_input_size = volume_size\n",
    "    else:\n",
    "        # larger sizer, crop at 200x200\n",
    "        net_input_size = (SMALL_INPUT_SIZE, SMALL_INPUT_SIZE)\n",
    "    deepgmseg_model = model.create_model(metadata['filters'],\n",
    "                                         net_input_size)\n",
    "\n",
    "    ### Inside model.py :: create_model() \n",
    "    input_height, input_width = input_size\n",
    "    inputs = Input((input_height, input_width, 1))\n",
    "```\n",
    "\n",
    "However, I think this _should_ be trivial to fix on the data side of things? e.g. We fix the input layer size to 200x200, then center + zero-pad any smaller input data to 200x200, then crop back to the original size afterwards.\n",
    "\n",
    "That shouldn't change the inference results, no? (Since we use the same pretrained model weights regardless of input size, then input size _should_ have no bearing.) Hmmm..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5495d397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import dev.deepseg_gm.model as model\n",
    "from spinalcordtoolbox.deepseg_gm.deepseg_gm import DataResource\n",
    "\n",
    "for model_name in ['large', 'challenge']:\n",
    "    # NB: This is needed to reset the layer numbers, so that each model has identically named layers\n",
    "    #     https://stackoverflow.com/questions/49123194/keras-reset-layer-numbers\n",
    "    K.clear_session()\n",
    "    \n",
    "    # 2a Loading Keras model\n",
    "    gmseg_model_challenge = DataResource('deepseg_gm_models')\n",
    "    model_path, metadata_path = model.MODELS[model_name]\n",
    "    metadata_abs_path = gmseg_model_challenge.get_file_path(metadata_path)\n",
    "    with open(metadata_abs_path) as fp:\n",
    "        metadata = json.load(fp)\n",
    "    deepgmseg_model = model.create_model(metadata['filters'])\n",
    "    model_abs_path = gmseg_model_challenge.get_file_path(model_path)\n",
    "    deepgmseg_model.load_weights(model_abs_path)\n",
    "    # print(deepgmseg_model.summary())\n",
    "    \n",
    "    # 2b Saving ONNX model\n",
    "    model_fname_gm_out = sct_dir_local_path('data', 'deepseg_gm_models', '{}_model.onnx'.format(model_name))\n",
    "    if not os.path.isfile(model_fname_gm_out):\n",
    "        onnx_model = keras2onnx.convert_keras(deepgmseg_model, f'gm_model_{model_name}', target_opset=TARGET_OPSET)\n",
    "        keras2onnx.save_model(onnx_model, model_fname_gm_out)\n",
    "        output_names[f\"gm_{model_name}\"] = [n.name for n in onnx_model.graph.output]   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c160d021",
   "metadata": {},
   "source": [
    "## 3. sct_deepseg_lesion models\n",
    "\n",
    "NB: sct_deepseg_lesion uses the same model type as the 3D patch version of sct_deepseg_sc? Huh! Interesting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a31960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dev.deepseg_sc.cnn_models_3d import load_trained_model, nn_architecture_seg_3d\n",
    "\n",
    "for contrast_type in ['t2', 't2_ax', 't2s']:\n",
    "    # NB: This is needed to reset the layer numbers, so that each model has identically named layers\n",
    "    #     https://stackoverflow.com/questions/49123194/keras-reset-layer-numbers\n",
    "    K.clear_session()\n",
    "    \n",
    "    # 3a Loading Keras model\n",
    "    model_fname_lesion = sct_dir_local_path('data', 'deepseg_lesion_models', '{}_lesion.h5'.format(contrast_type))\n",
    "    # - NB: The inference code in SCT uses \"load_trained_model()\" instead of the actual model architecture, e.g.:\n",
    "    #\n",
    "    #     seg_model_lesion_old = load_trained_model(model_fname_lesion)    \n",
    "    #     print(seg_model_lesion_old.summary())\n",
    "    #\n",
    "    # - This works, but we want to change the output layer name, so we need to use `nn_architecture_seg_3d` like\n",
    "    #   we do with `nn_architecture_seg` and `nn_architecture_ctr` in the earlier steps.\n",
    "    # - The problem is, the call to `nn_architecture_seg_3d` was undocumented, so I had to guess at which \n",
    "    #   parameters would create the correct architecture. \n",
    "    # - I also had to fix a bug in `nn_architecture_seg_3d`. \n",
    "    # - Because of these factors, it is dubious whether the call to `nn_architecture_seg_3d` actually produces\n",
    "    #   the correct ONNX file. So, the generated model file should be tested extensively.\n",
    "    if contrast_type == \"t2\":\n",
    "        seg_model_lesion = nn_architecture_seg_3d(input_shape=(1, 48, 48, 48), n_base_filters=16, depth=3)\n",
    "    elif contrast_type == \"t2_ax\":\n",
    "        seg_model_lesion = nn_architecture_seg_3d(input_shape=(1, 48, 48, 48), n_base_filters=16, depth=2)\n",
    "    elif contrast_type == \"t2s\":\n",
    "        seg_model_lesion = nn_architecture_seg_3d(input_shape=(1, 48, 48, 48), n_base_filters=8, depth=3)\n",
    "    seg_model_lesion.load_weights(model_fname_lesion)\n",
    "    # print(seg_model_lesion.summary())\n",
    "    \n",
    "    # 3b Saving ONNX model\n",
    "    model_fname_lesion_out = sct_dir_local_path('data', 'deepseg_lesion_models', '{}_lesion.onnx'.format(contrast_type))\n",
    "    if not os.path.isfile(model_fname_lesion_out):\n",
    "        onnx_model = keras2onnx.convert_keras(seg_model_lesion, f'lesion_model_{contrast_type}', target_opset=TARGET_OPSET)\n",
    "        keras2onnx.save_model(onnx_model, model_fname_lesion_out)\n",
    "        output_names[f\"{contrast_type}_lesion\"] = [n.name for n in onnx_model.graph.output]   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b044345b",
   "metadata": {},
   "source": [
    "## 4. Checking output channel names\n",
    "\n",
    "The names of the output channels are needed when using the ONNX model to perform inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087063d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
